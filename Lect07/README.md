## Лекция № 7. Признаковое описание и этап порождения признаков

### 1. Введение и связь с предыдущей лекцией

- Напоминание: ранее рассматривалась структура процесса машинного обучения и пример линейной регрессии.
- Цель текущей лекции — понять, **что происходит до и после этапа обучения модели**, и в частности — как формируется **признаковое описание объектов или событий**.

------

### 2. Однородность и измеримость признаков

- Для статистических и параметрических моделей требуется **однородное признаковое описание** — одинаковый набор признаков для всех объектов.
- Признаки должны быть **численно сопоставимы** — измеряемые величины, не зависящие от типа данных.
- Наглядный пример — попытка описания событий в текстовой форме и необходимость перевести описание в численное пространство.

------

### 3. Игровая демонстрация: «циферблат часов»

- Объект наблюдения — минутная стрелка часов.
- Целевая переменная — минутная компонента времени.
- Признаки — координаты конца стрелки *(x, y)*.
- Ошибки измерений вводят два типа неопределённости:
  - **Алиаторическая** — присущая природе процесса (физический шум, турбулентность и т. п.);
  - **Эпистемическая** — обусловленная неполным знанием о процессе.

------

### 4. Формулировка задачи и выбор меры качества

- Тип задачи — **восстановление регрессии** (аппроксимация минутной компоненты по координатам).
- **Функция потерь** — среднеквадратичное отклонение (MSE).
- **Мера качества** — RMSE («чем меньше, тем лучше»).
- Обсуждение связи между функцией потерь и мерой качества; указано, что они **могут не совпадать**.

------

### 5. Сравнение моделей разной сложности

- **Линейная регрессия**: слабая модель, RMSE ≈ 11–18 мин.
- **Полиномиальная регрессия (6-я степень)**: улучшение качества (RMSE ≈ 9,5 мин).
- **MLP (нейронная сеть)**: незначительное улучшение, RMSE ≈ 8,5 мин.
- Вывод: даже сложная модель не помогает, если **неправильно сформулировано признаковое описание**.

------

### 6. Порождение новых признаков (Feature Engineering)

- Показано, что **полином любой степени — это линейная регрессия по новым признакам**, полученным как функции исходных переменных.
- Введено понятие **feature engineering** — процесс создания новых признаков (степенные, перекрёстные, функциональные и т. д.).
- Демонстрация перехода от одномерных признаков к многомерным.
- Замечание о необходимости добавления столбца единиц (смещения) при ручной реализации линейной регрессии.
- В Scikit-learn для этого существует `PolynomialFeatures`.

------

### 7. Исправление постановки задачи

- Новое признаковое описание: вычисление **угла положения стрелки** по (x, y).
- Результат: **RMSE ≈ 0,2 мин** — почти идеальное соответствие.
- Интерпретация: ошибка близка к погрешности измерений.
- Вывод: правильное признаковое описание может радикально улучшить качество модели даже без усложнения самой модели.

------

### 8. Основные выводы (мораль лекции)

1. **Порождение признаков — ключевой этап** в подготовке данных.
2. Задача исследователя — помочь модели, используя знание о природе процесса.
3. Машинное обучение — инструмент, но не замена физическому пониманию явления.
4. Новые признаки могут быть вычисляемыми, измеряемыми или конструктивно создаваемыми.

------

### 9. Общая последовательность решения задачи с ML

1. **Формулировка задачи** (тип задачи, мера качества).
2. **Определение объектов/событий**, целевой переменной и признаков.
3. **Выбор модели** (тип, структура, гиперпараметры).
4. **Выбор функции потерь** — определяется предположением о распределении ошибок.
5. **Оптимизация** параметров модели → обучение.
6. **Оценка качества** и проверка гипотез о причинах ошибок.

------

### 10. О распределениях и выборе функции потерь

- Напоминание о выводе функции потерь из предположения о распределении ошибки:
  - Нормальное → MSE;
  - Лапласовское → MAE.
- Замечено, что деление на *n* в формулах — лишь нормировка, не влияющая на положение минимума.
- При несимметричных распределениях (Вейбул, гамма, экспоненциальное) — другие меры качества могут быть уместнее.

------

### 11. Пример: перевзвешивание ошибки

- Для ветра или осадков важны **экстремальные значения**.
- Показано, как ввести **веса** в формулу RMSE, чтобы придать больший вес редким экстремумам.
- Обсуждено различие между **перевзвешенной мерой качества** и исходной функцией потерь.

------

### 12. Гиперпараметры

- Гиперпараметры — структурные параметры модели, **не настраиваемые** при обучении (например, степень полинома, архитектура сети).
- Настройка гиперпараметров — выбор структуры перед оптимизацией параметров.

------

### 13. Финальные замечания

- Подчёркнута важность **проверки гипотез** при неудачах модели:
  - постановка задачи,
  - выбор признаков,
  - качество разметки,
  - корректность кода,
  - сама модель.
- Рекомендован подход *разработки через тестирование* — изменяем гипотезу и проверяем предсказуемые эффекты.
- Домашнее задание — реализация функции потерь для разных распределений и эксперимент с выбором меры качества.

------

**Конечная идея лекции:**

> Эффективность модели определяется не её сложностью, а **качеством сформулированных признаков** и пониманием исследователем сути процесса.