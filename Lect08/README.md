## Лекция № 8. Подготовка данных, стратегии разбиения выборок и основы оценки неопределённости

### 1. Введение и логика продолжения курса

- Лекция продолжает систематический разбор **последовательности решения задач машинного обучения**.
- После обсуждения моделей, функций потерь и мер качества (в предыдущей лекции) фокус смещается на **работу с данными**, их подготовку, корректное разбиение и оценку надёжности результатов.
- Подчёркнуто, что именно подготовка и контроль данных — **самая трудоёмкая и ответственная часть процесса машинного обучения**.

------

### 2. Подготовка и нормализация данных

- **Пункт 3 общей последовательности** — подготовка данных (data preprocessing).

- Основные подэтапы:

  1. Сбор и агрегация измерений;
  2. Очистка, фильтрация, устранение выбросов и пропусков;
  3. Приведение признаков к численной форме (стандартизация, нормализация);
  4. Кодирование категориальных признаков и текста;
  5. При необходимости — понижение размерности.

- **Нормализация и стандартизация**:

  - обязательна для всех параметрических моделей (линейная регрессия, нейросети и др.);
  - проводить её следует **только на исходных данных**, не после промежуточных трансформаций;
  - повторная стандартизация после фильтрации выбросов выполняется заново от исходных данных, чтобы избежать накопления численных ошибок.

- Ключевое правило:

  > Если модель параметрическая — первым делом нормализовать данные.

------

### 3. Обработка категориальных признаков

- Категориальные признаки — признаки с **ограниченным числом возможных значений**, не обладающие естественным порядком (например: красный/зелёный/жёлтый).
- Для параметрических моделей требуется **числовое представление**:
  - прямое присвоение чисел недопустимо (создаёт фиктивный порядок);
  - используется **one-hot кодирование**: для каждой категории создаётся отдельный бинарный признак (1 — категория присутствует, 0 — отсутствует);
  - размерность признакового пространства увеличивается пропорционально числу категорий.
- Для непараметрических моделей (например, деревьев решений) прямое кодирование не требуется, но в параметрических — обязательно.

------

### 4. Разбиение данных: обучение, валидация, тест

- **Нельзя оценивать качество на тех же данных, на которых обучалась модель.**
- Выделяются три подмножества:
  1. **Тренировочная выборка** — обучение параметров модели;
  2. **Валидационная** — подбор гиперпараметров;
  3. **Тестовая (отложенная)** — итоговая проверка качества после завершения обучения.
- Типичные пропорции: **70–75 % / 25–30 %** между обучением и тестом.
- **Тестовая выборка используется только один раз** — в конце эксперимента.

------

### 5. Оптимизация гиперпараметров

- Гиперпараметры — структурные характеристики модели, не оптимизируемые при обучении (например, степень полинома, количество слоёв в сети, тип функции потерь).
- Подбор гиперпараметров выполняется **по качеству на валидационной выборке**.
- Процесс:
  1. Выбрать набор гиперпараметров;
  2. Обучить модель на тренировочных данных;
  3. Проверить качество на валидации;
  4. Повторить цикл для разных гиперпараметров;
  5. Выбрать конфигурацию с наилучшим качеством.
- Функция потерь может рассматриваться как гиперпараметр (например, MSE vs MAE).

------

### 6. Проблема случайности и метод скользящего контроля (cross-validation)

- При единственном случайном разбиении результаты могут зависеть от случайной структуры подвыборок.
- Решение — **скользящий контроль** (*k-fold cross-validation*):
  1. Обучение и валидация повторяются **k раз** на разных сочетаниях фолдов;
  2. Получаются k значений метрики качества;
  3. Финальная оценка — среднее (или медиана) этих k значений.
- Этот подход снижает влияние случайности и обеспечивает более достоверную оценку.
- Обсуждена визуальная схема (k = 5), поясняющая идею «скользящей» валидации.

------

### 7. Стратегии сэмплирования и временная корреляция

- При работе с **временными рядами** обычное случайное перемешивание недопустимо:
  - соседние наблюдения автокоррелированы;
  - при случайном разбиении модель фактически тестируется на почти тех же данных, что использовались для обучения;
  - результат — **чрезмерно оптимистичная оценка качества**.
- Приведён пример из практики автора: переоценка модели с 97 % точности до 73 % после корректного разбиения.
- Для временных данных используется **блочное или стратифицированное сэмплирование**:
  - деление на дни, недели, месяцы — интервалы, превышающие **радиус автокорреляции**;
  - радиус автокорреляции — лаг Δt, при котором автокорреляция ≈ 0.
     Пример:
  - для кучевых облаков Δt ≈ 5 мин,
  - для слоистых — до 1 ч,
  - для океанических процессов — недели.

------

### 8. Оптимизация модели и оценка финального качества

- После подбора гиперпараметров модель обучается на полной тренировочной подвыборке.
- Финальное качество оценивается **только на тестовой выборке** — независимой и неиспользованной в процессе оптимизации.
- Параллельно можно оценивать неопределённость (см. далее).

------

### 9. Применение модели и проверка совместимости данных

Перед практическим использованием обученной модели необходимо убедиться, что:

1. Новые данные получены из **того же распределения**, что и обучающие;
2. Набор признаков идентичен (по составу и единицам измерения);
3. Для нормализации используются **коэффициенты, вычисленные на обучающей выборке**, а не пересчитанные по новым данным.

> Иначе модель «думает», что данные такие же, хотя их распределение уже изменилось.

------

### 10. Оценка неопределённости (введение)

- Отмечено различие между **ошибкой модели** и **неопределённостью результата**.

- Неопределённость — характеристика диапазона возможных значений, учитывающая как алиаторические, так и эпистемические источники (анонсировано как тема следующей лекции).

- Продемонстрирован пример с синтетическими данными:

  - аппроксимация временного ряда (вес тела во времени) линейной регрессией;

  - обсуждены нарушения предпосылок (автокорреляция, зависимость наблюдений);

  - показано, как записывается **функция ошибки линейной регрессии в матричном виде**:

  - $$
    \mathcal{L} = (y - \theta^TX)^\top (y - \theta^TX)
    $$


    где (X) — матрица «объект × признаки», (\theta) — вектор параметров, (y) — вектор целевой переменной.

  - Подчёркнута важность понимания этой матричной формы для дальнейшего изучения нейронных сетей и оценки неопределённости.

------

### 11. Основные выводы лекции

1. **Подготовка данных** — критический и самый затратный этап в ML-процессе.
2. **Нормализация и one-hot кодирование** обязательны для параметрических моделей.
3. **Разделение данных** на обучение / валидацию / тест — необходимое условие достоверности.
4. **Скользящий контроль (cross-validation)** обеспечивает надёжную оценку качества.
5. Для **временных и пространственных данных** требуются специальные стратегии сэмплирования, учитывающие автокорреляцию.
6. **Новые данные** должны обрабатываться и нормализовываться строго по тем же параметрам, что и обучающие.
7. Знание **матричной формы линейной регрессии** — база для понимания методов оптимизации и оценки неопределённости.

------

**Итоговая идея лекции:**

> Корректная подготовка и проверка данных важнее усложнения модели; достоверность аппроксимации или прогноза зачастую определяется не мощностью алгоритма, а строгостью методологии и контролем неопределённости.